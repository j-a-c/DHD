#!/bin/bash
# This script attempts to find the optimal hierarchical decomposition of the 
# input graph. Then, it randomly mutates that graph and attempt to find the
# dynamic hierarchical decomposition of the mutated graph.

# ------
# Configurable paramters for the job.
# ------


echo "Configuring job."

# ----
# Optimal hierarchy parameters
# ----

# Name of the graph file
GRAPH="graph_12"

# The number of nodes to process at a time
NODES_PER_RUN=5

# The number of levels in the hierarchy.
LEVELS=7

# The ILP solution file root name.
# This will be appended by the counter.
SOL_ROOT="tmp/out.sol"


# ----
# Mutations parameters
# ----

# The number of edges to mutate in the original graph
NUM_MUTATE=1

# The neighborhood size to choose from when selecting nodes to dynamically re-rank.
HOOD_SIZE=0

# Then maximum amount of levels a node can change when being re-ranked.
CHANGE=1


# ----
# Dynamic decomposition parameters
# ----

# Output for the solution to the mutated graph.
MUT_SOL_FILE="tmp/mut_sol.sol"

# The name of the file the mutated graph to store the mutated graph.
MUTATED_GRAPH="$GRAPH.mutate"

# ----
# Non-configurable paramters for the job.
# ----


# The number of nodes in the graph.
NODES_LEFT=`for WORD in $(cat $GRAPH)
do
	echo $WORD
done | sort -u | wc -l`

# Counter to distinguish different iterations.
COUNTER=1



# -------
# This part of the script attempts to find the optimal hierarchical 
# decompostition of the input graph.
# -------


echo "Setting up temporary workspace."
rm -rf tmp
mkdir -p tmp
clear

echo "Starting job."

# TODO run the job multiple times.

# Correct nodes per run if necessary.
if [ $NODES_LEFT -lt $NODES_PER_RUN ]
	then NODES_PER_RUN=$NODES_LEFT
fi

SOL_FILE="$SOL_ROOT$COUNTER"

# Run the job the first time.
java -jar DHD.jar -i $GRAPH -l $LEVELS -n $NODES_PER_RUN
scip -c "read tmp/temp.lp" -c "optimize" -c "write solution $SOL_FILE" -c "quit"
NODES_LEFT=$((NODES_LEFT-NODES_PER_RUN))

# Continue to run the job, specifying the previous output file.
while [ $NODES_LEFT -gt 0 ]; do
	if [ $NODES_LEFT -lt $NODES_PER_RUN ]
		then NODES_PER_RUN=$NODES_LEFT
	fi

	# While we still have edges left, at more nodes to the graph.
	java -jar DHD.jar -i $GRAPH -l $LEVELS -n $NODES_PER_RUN -p $SOL_FILE

	NODES_LEFT=$((NODES_LEFT-NODES_PER_RUN))
	COUNTER=$((COUNTER+1))
	SOL_FILE="$SOL_ROOT$COUNTER"

	scip -c "read tmp/temp.lp" -c "optimize" -c "write solution $SOL_FILE" -c "quit"
done

# Final job to merge the final results.
java -jar DHD.jar -f $SOL_FILE


# -------
# This part of the script randomly mutates the graph.
# -------

# Mutate the original graph
java -cp DHD.jar DHD.Mutator -i $GRAPH -o $MUTATED_GRAPH -n $NUM_MUTATE

# -------
# This part of the script dynamically solves the mutated graph.
# -------
java -cp DHD.jar DHD.PartialSolver -i $MUTATED_GRAPH -p "tmp/__state" -d $GRAPH -k $HOOD_SIZE -c $CHANGE -l $LEVELS
scip -c "read tmp/temp.lp" -c "optimize" -c "write solution $MUT_SOL_FILE" -c "quit"
